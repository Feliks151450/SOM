{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg\n",
    "from scipy import stats\n",
    "import scipy.ndimage as ndimage\n",
    "from datetime import date\n",
    "# import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import datetime  \n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(t, temp, climatologyPeriod=[None,None], pctile=90, windowHalfWidth=5, smoothPercentile=True, smoothPercentileWidth=31, minDuration=5, joinAcrossGaps=True, maxGap=2, maxPadLength=False, coldSpells=False, alternateClimatology=False):\n",
    "    '''\n",
    "\n",
    "    Applies the Hobday et al. (2016) marine heat wave definition to an input time\n",
    "    series of temp ('temp') along with a time vector ('t'). Outputs properties of\n",
    "    all detected marine heat waves.\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "      t       Time vector, in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "              [1D numpy array of length T]\n",
    "      temp    Temperature vector [1D numpy array of length T]\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "      mhw     Detected marine heat waves (MHWs). Each key (following list) is a\n",
    "              list of length N where N is the number of detected MHWs:\n",
    " \n",
    "        'time_start'           Start time of MHW [datetime format]\n",
    "        'time_end'             End time of MHW [datetime format]\n",
    "        'time_peak'            Time of MHW peak [datetime format]\n",
    "        'date_start'           Start date of MHW [datetime format]\n",
    "        'date_end'             End date of MHW [datetime format]\n",
    "        'date_peak'            Date of MHW peak [datetime format]\n",
    "        'index_start'          Start index of MHW\n",
    "        'index_end'            End index of MHW\n",
    "        'index_peak'           Index of MHW peak\n",
    "        'duration'             Duration of MHW [days]\n",
    "        'intensity_max'        Maximum (peak) intensity [deg. C]\n",
    "        'intensity_mean'       Mean intensity [deg. C]\n",
    "        'intensity_var'        Intensity variability [deg. C]\n",
    "        'intensity_cumulative' Cumulative intensity [deg. C x days]\n",
    "        'rate_onset'           Onset rate of MHW [deg. C / days]\n",
    "        'rate_decline'         Decline rate of MHW [deg. C / days]\n",
    "\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "\n",
    "        'category' is an integer category system (1, 2, 3, 4) based on the maximum intensity\n",
    "        in multiples of threshold exceedances, i.e., a value of 1 indicates the MHW\n",
    "        intensity (relative to the climatology) was >=1 times the value of the threshold (but\n",
    "        less than 2 times; relative to climatology, i.e., threshold - climatology).\n",
    "        Category types are defined as 1=strong, 2=moderate, 3=severe, 4=extreme. More details in\n",
    "        Hobday et al. (in prep., Oceanography). Also supplied are the duration of each of these\n",
    "        categories for each event.\n",
    "\n",
    "        'n_events'             A scalar integer (not a list) indicating the total\n",
    "                               number of detected MHW events\n",
    "\n",
    "      clim    Climatology of SST. Each key (following list) is a seasonally-varying\n",
    "              time series [1D numpy array of length T] of a particular measure:\n",
    "\n",
    "        'thresh'               Seasonally varying threshold (e.g., 90th percentile)\n",
    "        'seas'                 Climatological seasonal cycle\n",
    "        'missing'              A vector of TRUE/FALSE indicating which elements in \n",
    "                               temp were missing values for the MHWs detection\n",
    "\n",
    "    Options:\n",
    "\n",
    "      climatologyPeriod      Period over which climatology is calculated, specified\n",
    "                             as list of start and end years. Default is to calculate\n",
    "                             over the full range of years in the supplied time series.\n",
    "                             Alternate periods suppled as a list e.g. [1983,2012].\n",
    "      pctile                 Threshold percentile (%) for detection of extreme values\n",
    "                             (DEFAULT = 90)\n",
    "      windowHalfWidth        Width of window (one sided) about day-of-year used for\n",
    "                             the pooling of values and calculation of threshold percentile\n",
    "                             (DEFAULT = 5 [days])\n",
    "      smoothPercentile       Boolean switch indicating whether to smooth the threshold\n",
    "                             percentile timeseries with a moving average (DEFAULT = True)\n",
    "      smoothPercentileWidth  Width of moving average window for smoothing threshold\n",
    "                             (DEFAULT = 31 [days])\n",
    "      minDuration            Minimum duration for acceptance detected MHWs\n",
    "                             (DEFAULT = 5 [days])\n",
    "      joinAcrossGaps         Boolean switch indicating whether to join MHWs\n",
    "                             which occur before/after a short gap (DEFAULT = True)\n",
    "      maxGap                 Maximum length of gap allowed for the joining of MHWs\n",
    "                             (DEFAULT = 2 [days])\n",
    "      maxPadLength           Specifies the maximum length [days] over which to interpolate\n",
    "                             (pad) missing data (specified as nans) in input temp time series.\n",
    "                             i.e., any consecutive blocks of NaNs with length greater\n",
    "                             than maxPadLength will be left as NaN. Set as an integer.\n",
    "                             (DEFAULT = False, interpolates over all missing values).\n",
    "      coldSpells             Specifies if the code should detect cold events instead of\n",
    "                             heat events. (DEFAULT = False)\n",
    "      alternateClimatology   Specifies an alternate temperature time series to use for the\n",
    "                             calculation of the climatology. Format is as a list of numpy\n",
    "                             arrays: (1) the first element of the list is a time vector,\n",
    "                             in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "                             [1D numpy array of length TClim] and (2) the second element of\n",
    "                             the list is a temperature vector [1D numpy array of length TClim].\n",
    "                             (DEFAULT = False)\n",
    "\n",
    "    Notes:\n",
    "\n",
    "      1. This function assumes that the input time series consist of continuous daily values\n",
    "         with few missing values. Time ranges which start and end part-way through the calendar\n",
    "         year are supported.\n",
    "\n",
    "      2. This function supports leap years. This is done by ignoring Feb 29s for the initial\n",
    "         calculation of the climatology and threshold. The value of these for Feb 29 is then\n",
    "         linearly interpolated from the values for Feb 28 and Mar 1.\n",
    "\n",
    "      3. The calculation of onset and decline rates assumes that the heat wave started a half-day\n",
    "         before the start day and ended a half-day after the end-day. (This is consistent with the\n",
    "         duration definition as implemented, which assumes duration = end day - start day + 1.)\n",
    "\n",
    "      4. For the purposes of MHW detection, any missing temp values not interpolated over (through\n",
    "         optional maxPadLLength) will be set equal to the seasonal climatology. This means they will\n",
    "         trigger the end/start of any adjacent temp values which satisfy the MHW criteria.\n",
    "\n",
    "      5. If the code is used to detect cold events (coldSpells = True), then it works just as for heat\n",
    "         waves except that events are detected as deviations below the (100 - pctile)th percentile\n",
    "         (e.g., the 10th instead of 90th) for at least 5 days. Intensities are reported as negative\n",
    "         values and represent the temperature anomaly below climatology.\n",
    "\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb 2015\n",
    "\n",
    "    '''\n",
    "\n",
    "    #\n",
    "    # Initialize MHW output variable\n",
    "    #\n",
    "\n",
    "    mhw = {}\n",
    "    mhw['time_start'] = [] # datetime format\n",
    "    mhw['time_end'] = [] # datetime format\n",
    "    mhw['time_peak'] = [] # datetime format\n",
    "    mhw['date_start'] = [] # datetime format\n",
    "    mhw['date_end'] = [] # datetime format\n",
    "    mhw['date_peak'] = [] # datetime format\n",
    "    mhw['index_start'] = []\n",
    "    mhw['index_end'] = []\n",
    "    mhw['index_peak'] = []\n",
    "    mhw['duration'] = [] # [days]\n",
    "    mhw['intensity_mean'] = [] # [deg C]\n",
    "    mhw['intensity_cumulative'] = [] # [deg C]\n",
    "\n",
    "    #\n",
    "    # Time and dates vectors\n",
    "    #\n",
    "\n",
    "    # Generate vectors for year, month, day-of-month, and day-of-year\n",
    "    T = len(t)\n",
    "    year = np.zeros((T))\n",
    "    month = np.zeros((T))\n",
    "    day = np.zeros((T))\n",
    "    doy = np.zeros((T))\n",
    "    for i in range(T):\n",
    "        year[i] = date.fromordinal(t[i]).year\n",
    "        month[i] = date.fromordinal(t[i]).month\n",
    "        day[i] = date.fromordinal(t[i]).day\n",
    "    # Leap-year baseline for defining day-of-year values\n",
    "    year_leapYear = 2012 # This year was a leap-year and therefore doy in range of 1 to 366\n",
    "    t_leapYear = np.arange(date(year_leapYear, 1, 1).toordinal(),date(year_leapYear, 12, 31).toordinal()+1)\n",
    "    dates_leapYear = [date.fromordinal(tt.astype(int)) for tt in t_leapYear]\n",
    "    month_leapYear = np.zeros((len(t_leapYear)))\n",
    "    day_leapYear = np.zeros((len(t_leapYear)))\n",
    "    doy_leapYear = np.zeros((len(t_leapYear)))\n",
    "    for tt in range(len(t_leapYear)):\n",
    "        month_leapYear[tt] = date.fromordinal(t_leapYear[tt]).month\n",
    "        day_leapYear[tt] = date.fromordinal(t_leapYear[tt]).day\n",
    "        doy_leapYear[tt] = t_leapYear[tt] - date(date.fromordinal(t_leapYear[tt]).year,1,1).toordinal() + 1\n",
    "    # Calculate day-of-year values\n",
    "    for tt in range(T):\n",
    "        doy[tt] = doy_leapYear[(month_leapYear == month[tt]) * (day_leapYear == day[tt])]\n",
    "\n",
    "    # Constants (doy values for Feb-28 and Feb-29) for handling leap-years\n",
    "    feb28 = 59\n",
    "    feb29 = 60\n",
    "\n",
    "    # Set climatology period, if unset use full range of available data\n",
    "    if (climatologyPeriod[0] is None) or (climatologyPeriod[1] is None):\n",
    "        climatologyPeriod[0] = year[0]\n",
    "        climatologyPeriod[1] = year[-1]\n",
    "\n",
    "    #\n",
    "    # Calculate threshold and seasonal climatology (varying with day-of-year)\n",
    "    #\n",
    "\n",
    "    # if alternate temperature time series is supplied for the calculation of the climatology\n",
    "    if alternateClimatology:\n",
    "        tClim = alternateClimatology[0]\n",
    "        tempClim = alternateClimatology[1]\n",
    "        TClim = len(tClim)\n",
    "        yearClim = np.zeros((TClim))\n",
    "        monthClim = np.zeros((TClim))\n",
    "        dayClim = np.zeros((TClim))\n",
    "        doyClim = np.zeros((TClim))\n",
    "        for i in range(TClim):\n",
    "            yearClim[i] = date.fromordinal(tClim[i]).year\n",
    "            monthClim[i] = date.fromordinal(tClim[i]).month\n",
    "            dayClim[i] = date.fromordinal(tClim[i]).day\n",
    "            doyClim[i] = doy_leapYear[(month_leapYear == monthClim[i]) * (day_leapYear == dayClim[i])]\n",
    "    else:\n",
    "        tempClim = temp.copy()\n",
    "        TClim = np.array([T]).copy()[0]\n",
    "        yearClim = year.copy()\n",
    "        monthClim = month.copy()\n",
    "        dayClim = day.copy()\n",
    "        doyClim = doy.copy()\n",
    "    # Length of climatological year\n",
    "    lenClimYear = 366\n",
    "    # Start and end indices\n",
    "    clim_start = np.where(yearClim == climatologyPeriod[0])[0][0]\n",
    "    clim_end = np.where(yearClim == climatologyPeriod[1])[0][-1]\n",
    "    # Inialize arrays\n",
    "    thresh_climYear = np.NaN*np.zeros(lenClimYear)\n",
    "    seas_climYear = np.NaN*np.zeros(lenClimYear)\n",
    "    clim = {}\n",
    "    clim['thresh'] = np.NaN*np.zeros(TClim)\n",
    "    clim['seas'] = np.NaN*np.zeros(TClim)\n",
    "    # Loop over all day-of-year values, and calculate threshold and seasonal climatology across years\n",
    "    for d in range(1,lenClimYear+1):\n",
    "        # Special case for Feb 29\n",
    "        if d == feb29:\n",
    "            continue\n",
    "        # find all indices for each day of the year +/- windowHalfWidth and from them calculate the threshold\n",
    "        tt0 = np.where(doyClim[clim_start:clim_end+1] == d)[0] \n",
    "        # If this doy value does not exist (i.e. in 360-day calendars) then skip it\n",
    "        if len(tt0) == 0:\n",
    "            continue\n",
    "        tt = np.array([])\n",
    "        for w in range(-windowHalfWidth, windowHalfWidth+1):\n",
    "            tt = np.append(tt, clim_start+tt0 + w)\n",
    "        tt = tt[tt>=0] # Reject indices \"before\" the first element\n",
    "        tt = tt[tt<TClim] # Reject indices \"after\" the last element\n",
    "        # thresh_climYear[d-1] = np.percentile(nonans(tempClim[tt.astype(int)]), pctile)\n",
    "        # seas_climYear[d-1] = np.mean(nonans(tempClim[tt.astype(int)]))\n",
    "        thresh_climYear[d-1] = np.percentile(tempClim[tt.astype(int)], pctile)\n",
    "        seas_climYear[d-1] = np.mean(tempClim[tt.astype(int)])\n",
    "    # Special case for Feb 29\n",
    "    thresh_climYear[feb29-1] = 0.5*thresh_climYear[feb29-2] + 0.5*thresh_climYear[feb29]\n",
    "    seas_climYear[feb29-1] = 0.5*seas_climYear[feb29-2] + 0.5*seas_climYear[feb29]\n",
    "\n",
    "    # Smooth if desired\n",
    "    if smoothPercentile:\n",
    "        # If the climatology contains NaNs, then assume it is a <365-day year and deal accordingly\n",
    "        if np.sum(np.isnan(seas_climYear)) + np.sum(np.isnan(thresh_climYear)):\n",
    "            valid = ~np.isnan(thresh_climYear)\n",
    "            thresh_climYear[valid] = runavg(thresh_climYear[valid], smoothPercentileWidth)\n",
    "            valid = ~np.isnan(seas_climYear)\n",
    "            seas_climYear[valid] = runavg(seas_climYear[valid], smoothPercentileWidth)\n",
    "        # >= 365-day year\n",
    "        else:\n",
    "            thresh_climYear = runavg(thresh_climYear, smoothPercentileWidth)\n",
    "            seas_climYear = runavg(seas_climYear, smoothPercentileWidth)\n",
    "\n",
    "    # Generate threshold for full time series\n",
    "    clim['thresh'] = thresh_climYear[doy.astype(int)-1]\n",
    "    clim['seas'] = seas_climYear[doy.astype(int)-1]\n",
    "\n",
    "    # Save vector indicating which points in temp are missing values\n",
    "    clim['missing'] = np.isnan(temp)\n",
    "    # Set all remaining missing temp values equal to the climatology\n",
    "    temp[np.isnan(temp)] = clim['seas'][np.isnan(temp)]\n",
    "\n",
    "    #\n",
    "    # Find MHWs as exceedances above the threshold\n",
    "    #\n",
    "\n",
    "    # Time series of \"True\" when threshold is exceeded, \"False\" otherwise\n",
    "    exceed_bool = temp - clim['thresh']\n",
    "    exceed_bool[exceed_bool<=0] = False\n",
    "    exceed_bool[exceed_bool>0] = True\n",
    "    # Find contiguous regions of exceed_bool = True\n",
    "    events, n_events = ndimage.label(exceed_bool)\n",
    "\n",
    "    # Find all MHW events of duration >= minDuration\n",
    "    for ev in range(1,n_events+1):\n",
    "        event_duration = (events == ev).sum()\n",
    "        if event_duration < minDuration:\n",
    "            continue\n",
    "        mhw['time_start'].append(t[np.where(events == ev)[0][0]])\n",
    "        mhw['time_end'].append(t[np.where(events == ev)[0][-1]])\n",
    "\n",
    "    # Link heat waves that occur before and after a short gap (gap must be no longer than maxGap)\n",
    "    if joinAcrossGaps:\n",
    "        # Calculate gap length for each consecutive pair of events\n",
    "        gaps = np.array(mhw['time_start'][1:]) - np.array(mhw['time_end'][0:-1]) - 1\n",
    "        if len(gaps) > 0:\n",
    "            while gaps.min() <= maxGap:\n",
    "                # Find first short gap\n",
    "                ev = np.where(gaps <= maxGap)[0][0]\n",
    "                # Extend first MHW to encompass second MHW (including gap)\n",
    "                mhw['time_end'][ev] = mhw['time_end'][ev+1]\n",
    "                # Remove second event from record\n",
    "                del mhw['time_start'][ev+1]\n",
    "                del mhw['time_end'][ev+1]\n",
    "                # Calculate gap length for each consecutive pair of events\n",
    "                gaps = np.array(mhw['time_start'][1:]) - np.array(mhw['time_end'][0:-1]) - 1\n",
    "                if len(gaps) == 0:\n",
    "                    break\n",
    "\n",
    "    # Calculate marine heat wave properties\n",
    "    mhw['n_events'] = len(mhw['time_start'])\n",
    "    categories = np.array(['Moderate', 'Strong', 'Severe', 'Extreme'])\n",
    "    for ev in range(mhw['n_events']):\n",
    "        mhw['date_start'].append(date.fromordinal(mhw['time_start'][ev]))\n",
    "        mhw['date_end'].append(date.fromordinal(mhw['time_end'][ev]))\n",
    "        # Get SST series during MHW event, relative to both threshold and to seasonal climatology\n",
    "        tt_start = np.where(t==mhw['time_start'][ev])[0][0]\n",
    "        tt_end = np.where(t==mhw['time_end'][ev])[0][0]\n",
    "        mhw['index_start'].append(tt_start)\n",
    "        mhw['index_end'].append(tt_end)\n",
    "        temp_mhw = temp[tt_start:tt_end+1]\n",
    "        thresh_mhw = clim['thresh'][tt_start:tt_end+1]\n",
    "        seas_mhw = clim['seas'][tt_start:tt_end+1]\n",
    "        mhw_relSeas = temp_mhw - seas_mhw\n",
    "        # Find peak\n",
    "        tt_peak = np.argmax(mhw_relSeas)\n",
    "        mhw['time_peak'].append(mhw['time_start'][ev] + tt_peak)\n",
    "        mhw['date_peak'].append(date.fromordinal(mhw['time_start'][ev] + tt_peak))\n",
    "        mhw['index_peak'].append(tt_start + tt_peak)\n",
    "        # MHW Duration\n",
    "        mhw['duration'].append(len(mhw_relSeas))\n",
    "        # MHW Intensity metrics\n",
    "        mhw['intensity_mean'].append(mhw_relSeas.mean())\n",
    "        mhw['intensity_cumulative'].append(mhw_relSeas.sum())\n",
    " \n",
    "    return mhw, clim\n",
    "\n",
    "\n",
    "def blockAverage(t, mhw, clim=None, blockLength=1, removeMissing=False, temp=None):\n",
    "    '''\n",
    "\n",
    "    Calculate statistics of marine heatwave (MHW) properties averaged over blocks of\n",
    "    a specified length of time. Takes as input a collection of detected MHWs\n",
    "    (using the marineHeatWaves.detect function) and a time vector for the source\n",
    "    SST series.\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "      t       Time vector, in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "      mhw     Marine heat waves (MHWs) detected using marineHeatWaves.detect\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "      mhwBlock   Time series of block-averaged MHW properties. Each key (following list)\n",
    "                 is a list of length N where N is the number of blocks:\n",
    " \n",
    "        'years_start'          Start year blocks (inclusive)\n",
    "        'years_end'            End year of blocks (inclusive)\n",
    "        'years_centre'         Decimal year at centre of blocks\n",
    "        'count'                Total MHW count in each block\n",
    "        'duration'             Average MHW duration in each block [days]\n",
    "        'intensity_max'        Average MHW \"maximum (peak) intensity\" in each block [deg. C]\n",
    "        'intensity_max_max'    Maximum MHW \"maximum (peak) intensity\" in each block [deg. C]\n",
    "        'intensity_mean'       Average MHW \"mean intensity\" in each block [deg. C]\n",
    "        'intensity_var'        Average MHW \"intensity variability\" in each block [deg. C]\n",
    "        'intensity_cumulative' Average MHW \"cumulative intensity\" in each block [deg. C x days]\n",
    "        'rate_onset'           Average MHW onset rate in each block [deg. C / days]\n",
    "        'rate_decline'         Average MHW decline rate in each block [deg. C / days]\n",
    "        'total_days'           Total number of MHW days in each block [days]\n",
    "        'total_icum'           Total cumulative intensity over all MHWs in each block [deg. C x days]\n",
    "\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "\n",
    "    Options:\n",
    "\n",
    "      blockLength            Size of block (in years) over which to calculate the\n",
    "                             averaged MHW properties. Must be an integer greater than\n",
    "                             or equal to 1 (DEFAULT = 1 [year])\n",
    "      removeMissing          Boolean switch indicating whether to remove (set = NaN)\n",
    "                             statistics for any blocks in which there were missing \n",
    "                             temperature values (DEFAULT = FALSE)\n",
    "      clim                   The temperature climatology (including missing value information)\n",
    "                             as output by marineHeatWaves.detect (required if removeMissing = TRUE)\n",
    "      temp                   Temperature time series. If included mhwBlock will output block\n",
    "                             averages of mean, max, and min temperature (DEFAULT = NONE)\n",
    "\n",
    "                             If both clim and temp are provided, this will output annual counts\n",
    "                             of moderate, strong, severe, and extreme days.\n",
    "\n",
    "    Notes:\n",
    "\n",
    "      This function assumes that the input time vector consists of continuous daily values. Note that\n",
    "      in the case of time ranges which start and end part-way through the calendar year, the block\n",
    "      averages at the endpoints, for which there is less than a block length of data, will need to be\n",
    "      interpreted with care.\n",
    "\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb-Mar 2015\n",
    "\n",
    "    '''\n",
    "\n",
    "    #\n",
    "    # Time and dates vectors, and calculate block timing\n",
    "    #\n",
    "\n",
    "    # Generate vectors for year, month, day-of-month, and day-of-year\n",
    "    T = len(t)\n",
    "    year = np.zeros((T))\n",
    "    month = np.zeros((T))\n",
    "    day = np.zeros((T))\n",
    "    for i in range(T):\n",
    "        year[i] = date.fromordinal(t[i]).year\n",
    "        month[i] = date.fromordinal(t[i]).month\n",
    "        day[i] = date.fromordinal(t[i]).day\n",
    "\n",
    "    # Number of blocks, round up to include partial blocks at end\n",
    "    years = np.unique(year)\n",
    "    nBlocks = np.ceil((years.max() - years.min() + 1) / blockLength).astype(int)\n",
    "\n",
    "    #\n",
    "    # Temperature time series included?\n",
    "    #\n",
    "\n",
    "    sw_temp = None\n",
    "    sw_cats = None\n",
    "    if temp is not None:\n",
    "        sw_temp = True\n",
    "        if clim is not None:\n",
    "            sw_cats = True\n",
    "        else:\n",
    "            sw_cats = False\n",
    "    else:\n",
    "        sw_temp = False\n",
    "\n",
    "    #\n",
    "    # Initialize MHW output variable\n",
    "    #\n",
    "\n",
    "    mhwBlock = {}\n",
    "    mhwBlock['count'] = np.zeros(nBlocks)\n",
    "    mhwBlock['duration'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_mean'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_cumulative'] = np.zeros(nBlocks)\n",
    "    mhwBlock['total_days'] = np.zeros(nBlocks)\n",
    "    mhwBlock['total_icum'] = np.zeros(nBlocks)\n",
    "\n",
    "    # Start, end, and centre years for all blocks\n",
    "    mhwBlock['years_start'] = years[range(0, len(years), blockLength)]\n",
    "    mhwBlock['years_end'] = mhwBlock['years_start'] + blockLength - 1\n",
    "    mhwBlock['years_centre'] = 0.5*(mhwBlock['years_start'] + mhwBlock['years_end'])\n",
    "\n",
    "    #\n",
    "    # Calculate block averages\n",
    "    #\n",
    "\n",
    "    for i in range(mhw['n_events']):\n",
    "        # Block index for year of each MHW (MHW year defined by start year)\n",
    "        iBlock = np.where((mhwBlock['years_start'] <= mhw['date_start'][i].year) * (mhwBlock['years_end'] >= mhw['date_start'][i].year))[0][0]\n",
    "        # Add MHW properties to block count\n",
    "        mhwBlock['count'][iBlock] += 1\n",
    "        mhwBlock['duration'][iBlock] += mhw['duration'][i]\n",
    "        mhwBlock['intensity_mean'][iBlock] += mhw['intensity_mean'][i]\n",
    "        mhwBlock['intensity_cumulative'][iBlock] += mhw['intensity_cumulative'][i]\n",
    "        if mhw['date_start'][i].year == mhw['date_end'][i].year: # MHW in single year\n",
    "            mhwBlock['total_days'][iBlock] += mhw['duration'][i]\n",
    "            mhwBlock['total_icum'][iBlock] += mhw['intensity_cumulative'][i]\n",
    "        else: # MHW spans multiple years\n",
    "            year_mhw = year[mhw['index_start'][i]:mhw['index_end'][i]+1]\n",
    "            for yr_mhw in np.unique(year_mhw):\n",
    "                iBlock = np.where((mhwBlock['years_start'] <= yr_mhw) * (mhwBlock['years_end'] >= yr_mhw))[0][0]\n",
    "                mhwBlock['total_days'][iBlock] += np.sum(year_mhw == yr_mhw)\n",
    "                #HH: for each event, intensity_cumulative is distributed based on the number of days that fall on each block\n",
    "                mhwBlock['total_icum'][iBlock] += mhw['intensity_cumulative'][i] * np.sum(year_mhw == yr_mhw) / len(year_mhw)\n",
    "\n",
    "    # Calculate averages\n",
    "    count = 1.*mhwBlock['count']\n",
    "    count[count==0] = np.nan\n",
    "    mhwBlock['duration'] = mhwBlock['duration'] / count\n",
    "    mhwBlock['intensity_mean'] = mhwBlock['intensity_mean'] / count\n",
    "    mhwBlock['intensity_cumulative'] = mhwBlock['intensity_cumulative'] / count\n",
    "\n",
    "    return mhwBlock\n",
    "\n",
    "\n",
    "def meanTrend(mhwBlock, alpha=0.05):\n",
    "    '''\n",
    "\n",
    "    Calculates the mean and trend of marine heatwave (MHW) properties. Takes as input a\n",
    "    collection of block-averaged MHW properties (using the marineHeatWaves.blockAverage\n",
    "    function). Handles missing values (which should be specified by NaNs).\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "      mhwBlock      Time series of block-averaged MHW statistics calculated using the\n",
    "                    marineHeatWaves.blockAverage function\n",
    "      alpha         Significance level for estimate of confidence limits on trend, e.g.,\n",
    "                    alpha = 0.05 for 5% significance (or 95% confidence) (DEFAULT = 0.05)\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "      mean          Mean of all MHW properties over all block-averaged values\n",
    "      trend         Linear trend of all MHW properties over all block-averaged values\n",
    "      dtrend        One-sided width of (1-alpha)% confidence intevfal on linear trend,\n",
    "                    i.e., trend lies within (trend-dtrend, trend+dtrend) with specified\n",
    "                    level  of confidence.\n",
    "\n",
    "                    Both mean and trend have the following keys, the units the trend\n",
    "                    are the units of the property of interest per year:\n",
    "\n",
    "        'duration'             Duration of MHW [days]\n",
    "        'intensity_max'        Maximum (peak) intensity [deg. C]\n",
    "        'intensity_mean'       Mean intensity [deg. C]\n",
    "        'intensity_var'        Intensity variability [deg. C]\n",
    "        'intensity_cumulative' Cumulative intensity [deg. C x days]\n",
    "        'rate_onset'           Onset rate of MHW [deg. C / days]\n",
    "        'rate_decline'         Decline rate of MHW [deg. C / days]\n",
    "\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "\n",
    "    Notes:\n",
    "\n",
    "      This calculation performs a multiple linear regression of the form\n",
    "        y ~ beta * X + eps\n",
    "      where y is the MHW property of interest and X is a matrix of predictors. The first\n",
    "      column of X is all ones to estimate the mean, the second column is the time vector\n",
    "      which is taken as mhwBlock['years_centre'] and offset to be equal to zero at its\n",
    "      mid-point.\n",
    "\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb-Mar 2015\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Initialize mean and trend dictionaries\n",
    "    mean = {}\n",
    "    trend = {}\n",
    "    dtrend = {}\n",
    "\n",
    "    # Construct matrix of predictors, first column is all ones to estimate the mean,\n",
    "    # second column is the time vector, equal to zero at mid-point.\n",
    "    t = mhwBlock['years_centre']\n",
    "    X = np.array([np.ones(t.shape), t-t.mean()]).T\n",
    "\n",
    "    # Loop over all keys in mhwBlock\n",
    "    for key in mhwBlock.keys():\n",
    "        # Skip time-vector keys of mhwBlock\n",
    "        if (key == 'years_centre') + (key == 'years_end') + (key == 'years_start'):\n",
    "            continue\n",
    "\n",
    "        # Predictand (MHW property of interest)\n",
    "        y = mhwBlock[key]\n",
    "        valid = ~np.isnan(y) # non-NaN indices\n",
    "\n",
    "        # Perform linear regression over valid indices\n",
    "        if np.isinf(nonans(y).sum()): # If contains Inf values\n",
    "            beta = [np.nan, np.nan]\n",
    "        elif np.sum(~np.isnan(y)) > 0: # If at least one non-NaN value\n",
    "            beta = linalg.lstsq(X[valid,:], y[valid])[0]\n",
    "        else:\n",
    "            beta = [np.nan, np.nan]\n",
    "\n",
    "        # Insert regression coefficients into mean and trend dictionaries\n",
    "        mean[key] = beta[0]\n",
    "        trend[key] = beta[1]\n",
    "\n",
    "        # Confidence limits on trend\n",
    "        yhat = np.sum(beta*X, axis=1)\n",
    "        t_stat = stats.t.isf(alpha/2, len(t[valid])-2)\n",
    "        s = np.sqrt(np.sum((y[valid] - yhat[valid])**2) / (len(t[valid])-2))\n",
    "        Sxx = np.sum(X[valid,1]**2) - (np.sum(X[valid,1])**2)/len(t[valid]) # np.var(X, axis=1)[1]\n",
    "        dbeta1 = t_stat * s / np.sqrt(Sxx)\n",
    "        dtrend[key] = dbeta1\n",
    "\n",
    "    # Return mean, trend\n",
    "    return mean, trend, dtrend\n",
    "\n",
    "\n",
    "def rank(t, mhw):\n",
    "    '''\n",
    "\n",
    "    Calculate the rank and return periods of marine heatwaves (MHWs) according to\n",
    "    each metric. Takes as input a collection of detected MHWs (using the\n",
    "    marineHeatWaves.detect function) and a time vector for the source SST series.\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "      t       Time vector, in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "      mhw     Marine heat waves (MHWs) detected using marineHeatWaves.detect\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "      rank          The rank of each MHW according to each MHW property. A rank of 1 is the\n",
    "                    largest, 2 is the 2nd largest, etc. Each key (listed below) is a list\n",
    "                    of length N where N is the number of MHWs.\n",
    "\n",
    "      returnPeriod  The return period (in years) of each MHW according to each MHW property.\n",
    "                    The return period signifies, statistically, the recurrence interval for\n",
    "                    an event at least as large/long as the event in quetion. Each key (listed\n",
    "                    below) is a list of length N where N is the number of MHWs.\n",
    " \n",
    "        'duration'             Average MHW duration in each block [days]\n",
    "        'intensity_max'        Average MHW \"maximum (peak) intensity\" in each block [deg. C]\n",
    "        'intensity_mean'       Average MHW \"mean intensity\" in each block [deg. C]\n",
    "        'intensity_var'        Average MHW \"intensity variability\" in each block [deg. C]\n",
    "        'intensity_cumulative' Average MHW \"cumulative intensity\" in each block [deg. C x days]\n",
    "        'rate_onset'           Average MHW onset rate in each block [deg. C / days]\n",
    "        'rate_decline'         Average MHW decline rate in each block [deg. C / days]\n",
    "        'total_days'           Total number of MHW days in each block [days]\n",
    "        'total_icum'           Total cumulative intensity over all MHWs in each block [deg. C x days]\n",
    "\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "\n",
    "    Notes:\n",
    "\n",
    "      This function assumes that the MHWs were calculated over a suitably long record that return\n",
    "      periods make sense. If the record length is a few years or less than this becomes meaningless.\n",
    "\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Sep 2015\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Initialize rank and return period dictionaries\n",
    "    rank = {}\n",
    "    returnPeriod = {}\n",
    "\n",
    "    # Number of years on record\n",
    "    nYears = len(t)/365.25\n",
    "\n",
    "    # Loop over all keys in mhw\n",
    "    for key in mhw.keys():\n",
    "        # Skip irrelevant keys of mhw, only calculate rank/returns for MHW properties\n",
    "        if (key == 'date_end') + (key == 'date_peak') + (key == 'date_start') + (key == 'date_end') + (key == 'date_peak') + (key == 'date_start') + (key == 'index_end') + (key == 'index_peak') + (key == 'index_start') + (key == 'n_events'):\n",
    "            continue\n",
    "\n",
    "        # Calculate ranks\n",
    "        rank[key] = mhw['n_events'] - np.array(mhw[key]).argsort().argsort()  \n",
    "        # Calculate return period as (# years on record + 1) / (# of occurrences of event)\n",
    "        # Return period is for events of at least the event magnitude/duration\n",
    "        returnPeriod[key] = (nYears + 1) / rank[key]\n",
    "\n",
    "    # Return rank, return\n",
    "    return rank, returnPeriod\n",
    "\n",
    "\n",
    "def runavg(ts, w):\n",
    "    '''\n",
    "\n",
    "    Performs a running average of an input time series using uniform window\n",
    "    of width w. This function assumes that the input time series is periodic.\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "      ts            Time series [1D numpy array]\n",
    "      w             Integer length (must be odd) of running average window\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "      ts_smooth     Smoothed time series\n",
    "\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb-Mar 2015\n",
    "\n",
    "    '''\n",
    "    # Original length of ts\n",
    "    N = len(ts)\n",
    "    # make ts three-fold periodic\n",
    "    ts = np.append(ts, np.append(ts, ts))\n",
    "    # smooth by convolution with a window of equal weights\n",
    "    ts_smooth = np.convolve(ts, np.ones(w)/w, mode='same')\n",
    "    # Only output central section, of length equal to the original length of ts\n",
    "    ts = ts_smooth[N:2*N]\n",
    "\n",
    "    return ts\n",
    "\n",
    "\n",
    "def pad(data, maxPadLength=False):\n",
    "    '''\n",
    "\n",
    "    Linearly interpolate over missing data (NaNs) in a time series.\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "      data\t     Time series [1D numpy array]\n",
    "      maxPadLength   Specifies the maximum length over which to interpolate,\n",
    "                     i.e., any consecutive blocks of NaNs with length greater\n",
    "                     than maxPadLength will be left as NaN. Set as an integer.\n",
    "                     maxPadLength=False (default) interpolates over all NaNs.\n",
    "\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Jun 2015\n",
    "\n",
    "    '''\n",
    "    data_padded = data.copy()\n",
    "    bad_indexes = np.isnan(data)\n",
    "    good_indexes = np.logical_not(bad_indexes)\n",
    "    good_data = data[good_indexes]\n",
    "    interpolated = np.interp(bad_indexes.nonzero()[0], good_indexes.nonzero()[0], good_data)\n",
    "    data_padded[bad_indexes] = interpolated\n",
    "    if maxPadLength:\n",
    "        blocks, n_blocks = ndimage.label(np.isnan(data))\n",
    "        for bl in range(1, n_blocks+1):\n",
    "            if (blocks==bl).sum() > maxPadLength:\n",
    "                data_padded[blocks==bl] = np.nan\n",
    "\n",
    "    return data_padded\n",
    "\n",
    "\n",
    "def nonans(array):\n",
    "    '''\n",
    "    Return input array [1D numpy array] with\n",
    "    all nan values removed\n",
    "    '''\n",
    "    return array[~np.isnan(array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ispan(start,end,stride = 1):\n",
    "  n = int((end-start+1)/stride)\n",
    "  ts = [start+stride*i for i in range(0,n)]#range(0,n)最大只能n-1\n",
    "  return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "v cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/linlifei/SOM/test.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000001?line=68'>69</a>\u001b[0m time \u001b[39m=\u001b[39m ispan(time_start, time_end, \u001b[39m24\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000001?line=69'>70</a>\u001b[0m \u001b[39m# time = np.array(time)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000001?line=70'>71</a>\u001b[0m \u001b[39m# nonans(time.astype(int))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000001?line=71'>72</a>\u001b[0m \u001b[39m# time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000001?line=76'>77</a>\u001b[0m \u001b[39m# x[~np.isnan(x)]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000001?line=77'>78</a>\u001b[0m \u001b[39m# np.isnan(x)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000001?line=78'>79</a>\u001b[0m detect(time ,sst)\n",
      "\u001b[1;32m/Users/linlifei/SOM/test.ipynb Cell 2'\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(t, temp, climatologyPeriod, pctile, windowHalfWidth, smoothPercentile, smoothPercentileWidth, minDuration, joinAcrossGaps, maxGap, maxPadLength, coldSpells, alternateClimatology)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=243'>244</a>\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39misnan(seas_climYear)) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39misnan(thresh_climYear)):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=244'>245</a>\u001b[0m     valid \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(thresh_climYear)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=245'>246</a>\u001b[0m     thresh_climYear[valid] \u001b[39m=\u001b[39m runavg(thresh_climYear[valid], smoothPercentileWidth)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=246'>247</a>\u001b[0m     valid \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(seas_climYear)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=247'>248</a>\u001b[0m     seas_climYear[valid] \u001b[39m=\u001b[39m runavg(seas_climYear[valid], smoothPercentileWidth)\n",
      "\u001b[1;32m/Users/linlifei/SOM/test.ipynb Cell 2'\u001b[0m in \u001b[0;36mrunavg\u001b[0;34m(ts, w)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=671'>672</a>\u001b[0m ts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(ts, np\u001b[39m.\u001b[39mappend(ts, ts))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=672'>673</a>\u001b[0m \u001b[39m# smooth by convolution with a window of equal weights\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=673'>674</a>\u001b[0m ts_smooth \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconvolve(ts, np\u001b[39m.\u001b[39;49mones(w)\u001b[39m/\u001b[39;49mw, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=674'>675</a>\u001b[0m \u001b[39m# Only output central section, of length equal to the original length of ts\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/linlifei/SOM/test.ipynb#ch0000002?line=675'>676</a>\u001b[0m ts \u001b[39m=\u001b[39m ts_smooth[N:\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mN]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ncl_stable/lib/python3.10/site-packages/numpy/core/numeric.py:843\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/linlifei/opt/anaconda3/envs/ncl_stable/lib/python3.10/site-packages/numpy/core/numeric.py?line=840'>841</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39ma cannot be empty\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/linlifei/opt/anaconda3/envs/ncl_stable/lib/python3.10/site-packages/numpy/core/numeric.py?line=841'>842</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(v) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/linlifei/opt/anaconda3/envs/ncl_stable/lib/python3.10/site-packages/numpy/core/numeric.py?line=842'>843</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mv cannot be empty\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/linlifei/opt/anaconda3/envs/ncl_stable/lib/python3.10/site-packages/numpy/core/numeric.py?line=843'>844</a>\u001b[0m \u001b[39mreturn\u001b[39;00m multiarray\u001b[39m.\u001b[39mcorrelate(a, v[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], mode)\n",
      "\u001b[0;31mValueError\u001b[0m: v cannot be empty"
     ]
    }
   ],
   "source": [
    "#### --------------------  御用分隔符  -------------------- ####\n",
    "#### 读入数据\n",
    "f = '/Users/linlifei/data/sst_1982_2020.nc'\n",
    "tem = xr.open_dataset(f)\n",
    "sst = tem['sst']\n",
    "time = tem['time']\n",
    "# time\n",
    "# nc_obj= nc.Dataset('C:\\\\cygwin\\home\\Lenovo\\scripts\\SCSHeatwave\\sst_1982_2020.nc')\n",
    "\n",
    "# print(nc_obj)\n",
    "# print('---------------------------------------') \n",
    "\n",
    "# #查看nc文件中的变量\n",
    "# #print(nc_obj.variables.keys())\n",
    "# for i in nc_obj.variables.keys():\n",
    "#  print(i)\n",
    "#  print('---------------------------------------')\n",
    "\n",
    "# #查看每个变量的信息\n",
    "# #print(nc_obj.variables['lat'])\n",
    "# #print(nc_obj.variables['lon'])\n",
    "# #print(nc_obj.variables['time'])\n",
    "# #print(nc_obj.variables['sst'])\n",
    "# #print('---------------------------------------')\n",
    " \n",
    "# #查看每个变量的属性\n",
    "# #print(nc_obj.variables['lat'].ncattrs())\n",
    "# #print(nc_obj.variables['lon'].ncattrs())\n",
    "# #print(nc_obj.variables['sst'].ncattrs())\n",
    "# #print(nc_obj.variables['time'].ncattrs())\n",
    "# #print(nc_obj.variables['lat'].units)\n",
    "# #print(nc_obj.variables['lon'].units)\n",
    " \n",
    "# print('---------------------------------------')\n",
    "\n",
    "\n",
    "# #读取数据值\n",
    "# lat=(nc_obj.variables['lat'][:])\n",
    "# lon=(nc_obj.variables['lon'][:])\n",
    "# sst=(nc_obj.variables['sst'][:])\n",
    "# time =(nc_obj.variables['time'][:])\n",
    "# time\n",
    "# #pd.Series(time).to_csv('time.csv')\n",
    "# print(time)\n",
    "# times = nc.num2date(time[:],'hours since 1800-01-01 00:00:0.0')\n",
    "# print(times)\n",
    "# #将时间转为datetime格式\n",
    "# #dateArray =  datetime.datetime.utcfromtimestamp(times)\n",
    "# time\n",
    "# time.dt.strftime(\"%Y%M\")\n",
    "# time.to_datetime()\n",
    "# time_test = pd.to_datetime(time)\n",
    "# time_test\n",
    "# time_test0 = pd.Timestamp(time_test)\n",
    "# a = date(1982,6,1).toordinal()\n",
    "# a\n",
    "# time_test = time['time'].values\n",
    "# time_test = pd.to_datetime(time)\n",
    "# time_test\n",
    "# datetime.datetime.utcfromtimestamp(time)\n",
    "# 66474+657072\n",
    "# 657072:1800,1,1\n",
    "# 723697:1982,6,1\n",
    "\n",
    "#  datetime(time)\n",
    "# print(mhw)\n",
    "time_start = date(1982,6,1).toordinal()\n",
    "time_end = date(2020,8,31).toordinal()\n",
    "time = ispan(time_start, time_end, 24)\n",
    "# time = np.array(time)\n",
    "# nonans(time.astype(int))\n",
    "# time\n",
    "# sst\n",
    "# x = sst.loc['1982-06-01',:,1.125]\n",
    "# x = [1400, 1500, 1600, nan, nan, nan ,1700]\n",
    "# x\n",
    "# x[~np.isnan(x)]\n",
    "# np.isnan(x)\n",
    "detect(time ,sst)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb645f5ac802746a3f918b2fa56e74d680827e4b5eb0b066989188ef382de0a4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ncl_stable')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
